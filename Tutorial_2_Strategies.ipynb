{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will take a closer look at strategies in the context of both multi-step forecasting and simultaneous forecasting of multiple time series.\n",
    "\n",
    "We will explore how strategies affect the feature generation process used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything we need and define functions to obtain the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from copy import deepcopy\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tsururu.dataset import IndexSlicer, Pipeline, TSDataset\n",
    "from tsururu.model_training.trainer import DLTrainer, MLTrainer\n",
    "from tsururu.model_training.validator import KFoldCrossValidator\n",
    "from tsururu.models.boost import CatBoost\n",
    "from tsururu.strategies import (\n",
    "    DirectStrategy,\n",
    "    FlatWideMIMOStrategy,\n",
    "    MIMOStrategy,\n",
    "    RecursiveStrategy,\n",
    ")\n",
    "from tsururu.strategies.base import Strategy\n",
    "from tsururu.strategies.utils import timing_decorator\n",
    "from tsururu.transformers import (\n",
    "    DateSeasonsGenerator,\n",
    "    DifferenceNormalizer,\n",
    "    LagTransformer,\n",
    "    LastKnownNormalizer,\n",
    "    SequentialTransformer,\n",
    "    StandardScalerTransformer,\n",
    "    TargetGenerator,\n",
    "    UnionTransformer,\n",
    ")\n",
    "\n",
    "index_slicer = IndexSlicer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transfer the necessary code into the notebook so that we can output the values of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveStrategy(Strategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: int,\n",
    "        trainer: Union[MLTrainer, DLTrainer],\n",
    "        pipeline: Pipeline,\n",
    "        step: int = 1,\n",
    "        model_horizon: int = 1,\n",
    "        reduced: bool = False,\n",
    "    ):\n",
    "        super().__init__(horizon, history, trainer, pipeline, step)\n",
    "        self.model_horizon = model_horizon\n",
    "        self.reduced = reduced\n",
    "        self.strategy_name = \"recursive\"\n",
    "\n",
    "    @timing_decorator\n",
    "    def fit(\n",
    "        self,\n",
    "        dataset: TSDataset,\n",
    "    ) -> \"RecursiveStrategy\":\n",
    "        features_idx = index_slicer.create_idx_data(\n",
    "            dataset.data,\n",
    "            self.model_horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )\n",
    "\n",
    "        target_idx = index_slicer.create_idx_target(\n",
    "            dataset.data,\n",
    "            self.model_horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )\n",
    "\n",
    "        data = self.pipeline.create_data_dict_for_pipeline(dataset, features_idx, target_idx)\n",
    "        data = self.pipeline.fit_transform(data, self.strategy_name)\n",
    "\n",
    "        val_dataset = self.trainer.validation_params.get(\"validation_data\")\n",
    "\n",
    "        if val_dataset:\n",
    "            val_features_idx = index_slicer.create_idx_data(\n",
    "                val_dataset.data,\n",
    "                self.model_horizon,\n",
    "                self.history,\n",
    "                self.step,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            val_target_idx = index_slicer.create_idx_target(\n",
    "                val_dataset.data,\n",
    "                self.model_horizon,\n",
    "                self.history,\n",
    "                self.step,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            val_data = self.pipeline.create_data_dict_for_pipeline(\n",
    "                val_dataset, val_features_idx, val_target_idx\n",
    "            )\n",
    "            val_data = self.pipeline.transform(val_data)\n",
    "        else:\n",
    "            val_data = None\n",
    "\n",
    "        if isinstance(self.trainer, DLTrainer):\n",
    "            if self.strategy_name == \"FlatWideMIMOStrategy\":\n",
    "                self.trainer.horizon = 1\n",
    "            else:\n",
    "                self.trainer.horizon = self.model_horizon\n",
    "            self.trainer.history = self.history\n",
    "\n",
    "        current_trainer = deepcopy(self.trainer)\n",
    "\n",
    "        # In Recursive strategy, we train the individual model\n",
    "        if isinstance(current_trainer, DLTrainer):\n",
    "            checkpoint_path = current_trainer.checkpoint_path\n",
    "            pretrained_path = current_trainer.pretrained_path\n",
    "\n",
    "            current_trainer.checkpoint_path /= \"trainer_0\"\n",
    "            if pretrained_path:\n",
    "                current_trainer.pretrained_path /= \"trainer_0\"\n",
    "\n",
    "        current_trainer.fit(data, self.pipeline, val_data)\n",
    "\n",
    "        if isinstance(current_trainer, DLTrainer):\n",
    "            current_trainer.checkpoint_path = checkpoint_path\n",
    "            current_trainer.pretrained_path = pretrained_path\n",
    "\n",
    "        self.trainers.append(current_trainer)\n",
    "        return self\n",
    "\n",
    "    def make_step(self, step: int, dataset: TSDataset) -> TSDataset:\n",
    "        test_idx = index_slicer.create_idx_test(\n",
    "            dataset.data,\n",
    "            self.horizon - step * self.model_horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )\n",
    "\n",
    "        target_idx = index_slicer.create_idx_target(\n",
    "            dataset.data,\n",
    "            self.horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )[:, self.model_horizon * step : self.model_horizon * (step + 1)]\n",
    "\n",
    "        data = self.pipeline.create_data_dict_for_pipeline(dataset, test_idx, target_idx)\n",
    "        data = self.pipeline.transform(data)\n",
    "\n",
    "        pred = self.trainers[0].predict(data, self.pipeline)\n",
    "        pred = self.pipeline.inverse_transform_y(pred)\n",
    "\n",
    "        dataset.data.loc[target_idx.reshape(-1), dataset.target_column] = pred.reshape(-1)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    @timing_decorator\n",
    "    def predict(self, dataset: TSDataset, test_all: bool = False) -> pd.DataFrame:\n",
    "        new_data = dataset.make_padded_test(\n",
    "            self.horizon, self.history, test_all=test_all, step=self.step\n",
    "        )\n",
    "        new_dataset = TSDataset(new_data, dataset.columns_params, dataset.delta)\n",
    "\n",
    "        if test_all:\n",
    "            new_dataset.data = new_dataset.data.sort_values(\n",
    "                [dataset.id_column, \"segment_col\", dataset.date_column]\n",
    "            )\n",
    "\n",
    "        if self.reduced:\n",
    "            current_test_ids = index_slicer.create_idx_data(\n",
    "                new_dataset.data,\n",
    "                self.model_horizon,\n",
    "                self.history,\n",
    "                step=self.model_horizon,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            target_ids = index_slicer.create_idx_target(\n",
    "                new_dataset.data,\n",
    "                self.horizon,\n",
    "                self.history,\n",
    "                step=self.model_horizon,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            data = self.pipeline.create_data_dict_for_pipeline(\n",
    "                new_dataset, current_test_ids, target_ids\n",
    "            )\n",
    "            data = self.pipeline.transform(data)\n",
    "\n",
    "            pred = self.trainers[0].predict(data, self.pipeline)\n",
    "            pred = self.pipeline.inverse_transform_y(pred)\n",
    "\n",
    "            new_dataset.data.loc[target_ids.reshape(-1), dataset.target_column] = pred.reshape(-1)\n",
    "\n",
    "        else:\n",
    "            for step in range(self.horizon // self.model_horizon):\n",
    "                new_dataset = self.make_step(step, new_dataset)\n",
    "\n",
    "        # Get dataframe with predictions only\n",
    "        pred_df = self._make_preds_df(new_dataset, self.horizon, self.history)\n",
    "        return pred_df\n",
    "\n",
    "class MIMOStrategy(RecursiveStrategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: int,\n",
    "        trainer: Union[MLTrainer, DLTrainer],\n",
    "        pipeline: Pipeline,\n",
    "        step: int = 1,\n",
    "    ):\n",
    "        super().__init__(horizon, history, trainer, pipeline, step, model_horizon=horizon)\n",
    "        self.strategy_name = \"MIMOStrategy\"\n",
    "\n",
    "class DirectStrategy(RecursiveStrategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: int,\n",
    "        trainer: Union[MLTrainer, DLTrainer],\n",
    "        pipeline: Pipeline,\n",
    "        step: int = 1,\n",
    "        model_horizon: int = 1,\n",
    "        equal_train_size: bool = False,\n",
    "    ):\n",
    "        super().__init__(horizon, history, trainer, pipeline, step, model_horizon)\n",
    "        self.equal_train_size = equal_train_size\n",
    "        self.strategy_name = \"direct\"\n",
    "\n",
    "    @timing_decorator\n",
    "    def fit(\n",
    "        self,\n",
    "        dataset: TSDataset,\n",
    "    ) -> \"DirectStrategy\":\n",
    "        self.trainers = []\n",
    "\n",
    "        if self.equal_train_size:\n",
    "            features_idx = index_slicer.create_idx_data(\n",
    "                dataset.data,\n",
    "                self.model_horizon,\n",
    "                self.history,\n",
    "                self.step,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            target_idx = index_slicer.create_idx_target(\n",
    "                dataset.data,\n",
    "                self.model_horizon,\n",
    "                self.history,\n",
    "                self.step,\n",
    "                date_column=dataset.date_column,\n",
    "                delta=dataset.delta,\n",
    "            )\n",
    "\n",
    "            data = self.pipeline.create_data_dict_for_pipeline(dataset, features_idx, target_idx)\n",
    "            data = self.pipeline.fit_transform(data, self.strategy_name)\n",
    "\n",
    "            val_dataset = self.trainer.validation_params.get(\"validation_data\")\n",
    "\n",
    "            if val_dataset:\n",
    "                val_features_idx = index_slicer.create_idx_data(\n",
    "                    val_dataset.data,\n",
    "                    self.model_horizon,\n",
    "                    self.history,\n",
    "                    self.step,\n",
    "                    date_column=val_dataset.date_column,\n",
    "                    delta=val_dataset.delta,\n",
    "                )\n",
    "\n",
    "                val_target_idx = index_slicer.create_idx_target(\n",
    "                    val_dataset.data,\n",
    "                    self.model_horizon,\n",
    "                    self.history,\n",
    "                    self.step,\n",
    "                    date_column=val_dataset.date_column,\n",
    "                    delta=val_dataset.delta,\n",
    "                )\n",
    "\n",
    "                val_data = self.pipeline.create_data_dict_for_pipeline(\n",
    "                    val_dataset, val_features_idx, val_target_idx\n",
    "                )\n",
    "                val_data = self.pipeline.transform(val_data)\n",
    "            else:\n",
    "                val_data = None\n",
    "\n",
    "            for model_i, horizon in enumerate(range(1, self.horizon // self.model_horizon + 1)):\n",
    "                target_idx = index_slicer.create_idx_target(\n",
    "                    dataset.data,\n",
    "                    self.horizon,\n",
    "                    self.history,\n",
    "                    self.step,\n",
    "                    date_column=dataset.date_column,\n",
    "                    delta=dataset.delta,\n",
    "                )[:, (horizon - 1) * self.model_horizon : horizon * self.model_horizon]\n",
    "\n",
    "                data[\"target_idx\"] = target_idx\n",
    "\n",
    "                if val_dataset:\n",
    "                    val_target_idx = index_slicer.create_idx_target(\n",
    "                        val_dataset.data,\n",
    "                        self.horizon,\n",
    "                        self.history,\n",
    "                        self.step,\n",
    "                        date_column=val_dataset.date_column,\n",
    "                        delta=val_dataset.delta,\n",
    "                    )[:, (horizon - 1) * self.model_horizon : horizon * self.model_horizon]\n",
    "\n",
    "                    val_data[\"target_idx\"] = val_target_idx\n",
    "\n",
    "                if isinstance(self.trainer, DLTrainer):\n",
    "                    self.trainer.horizon = self.model_horizon\n",
    "                    self.trainer.history = self.history\n",
    "\n",
    "                current_trainer = deepcopy(self.trainer)\n",
    "\n",
    "                # In Direct strategy, we train several models, one for each model_horizon\n",
    "                if isinstance(current_trainer, DLTrainer):\n",
    "                    checkpoint_path = current_trainer.checkpoint_path\n",
    "                    pretrained_path = current_trainer.pretrained_path\n",
    "\n",
    "                    current_trainer.checkpoint_path /= f\"trainer_{model_i}\"\n",
    "                    if pretrained_path:\n",
    "                        current_trainer.pretrained_path /= f\"trainer_{model_i}\"\n",
    "\n",
    "                current_trainer.fit(data, self.pipeline, val_data)\n",
    "\n",
    "                if isinstance(current_trainer, DLTrainer):\n",
    "                    current_trainer.checkpoint_path = checkpoint_path\n",
    "                    current_trainer.pretrained_path = pretrained_path\n",
    "\n",
    "                self.trainers.append(current_trainer)\n",
    "\n",
    "        else:\n",
    "            for model_i, horizon in enumerate(range(1, self.horizon // self.model_horizon + 1)):\n",
    "                features_idx = index_slicer.create_idx_data(\n",
    "                    dataset.data,\n",
    "                    self.model_horizon * horizon,\n",
    "                    self.history,\n",
    "                    self.step,\n",
    "                    date_column=dataset.date_column,\n",
    "                    delta=dataset.delta,\n",
    "                )\n",
    "\n",
    "                target_idx = index_slicer.create_idx_target(\n",
    "                    dataset.data,\n",
    "                    self.model_horizon * horizon,\n",
    "                    self.history,\n",
    "                    self.step,\n",
    "                    date_column=dataset.date_column,\n",
    "                    delta=dataset.delta,\n",
    "                    n_last_horizon=self.model_horizon,\n",
    "                )\n",
    "\n",
    "                data = self.pipeline.create_data_dict_for_pipeline(\n",
    "                    dataset, features_idx, target_idx\n",
    "                )\n",
    "                data = self.pipeline.fit_transform(data, self.strategy_name)\n",
    "\n",
    "                val_dataset = self.trainer.validation_params.get(\"validation_data\")\n",
    "\n",
    "                if val_dataset:\n",
    "                    val_features_idx = index_slicer.create_idx_data(\n",
    "                        val_dataset.data,\n",
    "                        self.model_horizon * horizon,\n",
    "                        self.history,\n",
    "                        self.step,\n",
    "                        date_column=val_dataset.date_column,\n",
    "                        delta=val_dataset.delta,\n",
    "                    )\n",
    "\n",
    "                    val_target_idx = index_slicer.create_idx_target(\n",
    "                        val_dataset.data,\n",
    "                        self.model_horizon * horizon,\n",
    "                        self.history,\n",
    "                        self.step,\n",
    "                        date_column=val_dataset.date_column,\n",
    "                        delta=val_dataset.delta,\n",
    "                        n_last_horizon=self.model_horizon,\n",
    "                    )\n",
    "\n",
    "                    val_data = self.pipeline.create_data_dict_for_pipeline(\n",
    "                        val_dataset, val_features_idx, val_target_idx\n",
    "                    )\n",
    "                    val_data = self.pipeline.transform(val_data)\n",
    "                else:\n",
    "                    val_data = None\n",
    "\n",
    "                if isinstance(self.trainer, DLTrainer):\n",
    "                    self.trainer.horizon = self.model_horizon\n",
    "                    self.trainer.history = self.history\n",
    "\n",
    "                current_trainer = deepcopy(self.trainer)\n",
    "\n",
    "                # In Direct strategy, we train several models, one for each model_horizon\n",
    "                if isinstance(current_trainer, DLTrainer):\n",
    "                    checkpoint_path = current_trainer.checkpoint_path\n",
    "                    pretrained_path = current_trainer.pretrained_path\n",
    "\n",
    "                    current_trainer.checkpoint_path /= f\"trainer_{model_i}\"\n",
    "                    if pretrained_path:\n",
    "                        current_trainer.pretrained_path /= f\"trainer_{model_i}\"\n",
    "\n",
    "                current_trainer.fit(data, self.pipeline, val_data)\n",
    "\n",
    "                if isinstance(current_trainer, DLTrainer):\n",
    "                    current_trainer.checkpoint_path = checkpoint_path\n",
    "                    current_trainer.pretrained_path = pretrained_path\n",
    "\n",
    "                self.trainers.append(current_trainer)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def make_step(self, step, dataset):\n",
    "        test_idx = index_slicer.create_idx_test(\n",
    "            dataset.data,\n",
    "            self.horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )\n",
    "        target_idx = index_slicer.create_idx_target(\n",
    "            dataset.data,\n",
    "            self.horizon,\n",
    "            self.history,\n",
    "            self.step,\n",
    "            date_column=dataset.date_column,\n",
    "            delta=dataset.delta,\n",
    "        )[:, self.model_horizon * step : self.model_horizon * (step + 1)]\n",
    "\n",
    "        data = self.pipeline.create_data_dict_for_pipeline(dataset, test_idx, target_idx)\n",
    "        data = self.pipeline.transform(data)\n",
    "\n",
    "        pred = self.trainers[step].predict(data, self.pipeline)\n",
    "        pred = self.pipeline.inverse_transform_y(pred)\n",
    "\n",
    "        dataset.data.loc[target_idx.reshape(-1), dataset.target_column] = pred.reshape(-1)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "class FlatWideMIMOStrategy(MIMOStrategy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        horizon: int,\n",
    "        history: int,\n",
    "        trainer: Union[MLTrainer, DLTrainer],\n",
    "        pipeline: Pipeline,\n",
    "        step: int = 1,\n",
    "    ):\n",
    "        super().__init__(horizon, history, trainer, pipeline, step)\n",
    "        self.strategy_name = \"FlatWideMIMOStrategy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to track and understand how features and targets are generated depending on the strategy, we will use a synthetic series with the following structure:\n",
    "- 10 series, each with 1000 points.\n",
    "- The value in the `value` column is represented as `{id - 1}{point}`, meaning it is a concatenation of the series ID and the time point number within that series. For example, the value `5234` corresponds to the 234th point in the series with `id=4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1005</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1006</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1007</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1008</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1009</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value        date  id\n",
       "0   1000  2020-01-01   0\n",
       "1   1001  2020-01-02   0\n",
       "2   1002  2020-01-03   0\n",
       "3   1003  2020-01-04   0\n",
       "4   1004  2020-01-05   0\n",
       "5   1005  2020-01-06   0\n",
       "6   1006  2020-01-07   0\n",
       "7   1007  2020-01-08   0\n",
       "8   1008  2020-01-09   0\n",
       "9   1009  2020-01-10   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>3000</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>3001</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>3002</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>3003</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>3004</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>3005</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>3006</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>3007</td>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>3008</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>3009</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      value        date  id\n",
       "2000   3000  2020-01-01   2\n",
       "2001   3001  2020-01-02   2\n",
       "2002   3002  2020-01-03   2\n",
       "2003   3003  2020-01-04   2\n",
       "2004   3004  2020-01-05   2\n",
       "2005   3005  2020-01-06   2\n",
       "2006   3006  2020-01-07   2\n",
       "2007   3007  2020-01-08   2\n",
       "2008   3008  2020-01-09   2\n",
       "2009   3009  2020-01-10   2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/global/simulated_data_to_check.csv\")\n",
    "display(df.iloc[:10])\n",
    "display(df.iloc[2000:2010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "history = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freq: Day; period: 1\n"
     ]
    }
   ],
   "source": [
    "dataset_params = {\n",
    "    \"target\": {\n",
    "        \"columns\": [\"value\"],\n",
    "        \"type\": \"continious\",\n",
    "    },\n",
    "    \"date\": {\n",
    "        \"columns\": [\"date\"],\n",
    "        \"type\": \"datetime\",\n",
    "    },\n",
    "    \"id\": {\n",
    "        \"columns\": [\"id\"],\n",
    "        \"type\": \"categorical\",\n",
    "    }\n",
    "}\n",
    "\n",
    "dataset = TSDataset(\n",
    "    data=df,\n",
    "    columns_params=dataset_params,\n",
    "    print_freq_period_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_easy_params = {\n",
    "    \"target_lags\": 7,\n",
    "    \"date_lags\": 3,\n",
    "}\n",
    "\n",
    "# Configure the model parameters\n",
    "model = CatBoost\n",
    "model_params = {\n",
    "    \"loss_function\": \"MultiRMSE\",\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"verbose\": 500,\n",
    "}\n",
    "\n",
    "# Configure the validation parameters\n",
    "validation = KFoldCrossValidator\n",
    "validation_params = {\n",
    "    \"n_splits\": 2,\n",
    "}\n",
    "\n",
    "trainer_params = {}\n",
    "trainer = MLTrainer(\n",
    "    model,\n",
    "    model_params,\n",
    "    validation,\n",
    "    validation_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Multi-series prediction strategies:__\n",
    "\n",
    "- **Local-modelling**:\n",
    "  - An individual model for each time series. \n",
    "  - Each time series as independent from others.\n",
    "\n",
    "- **Global-modelling**:\n",
    "  - A single model for all time series.\n",
    "  - Features created from each series do not overlap with other series. Series are related but modeled separately.\n",
    "\n",
    "- **Multivariate-modelling**:\n",
    "  - A single model for all time series. \n",
    "  - Features created from each series are concatenated at each time step. Try to capture dependencies between the series at the same time point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-point-ahead prediction strategies:**\n",
    "\n",
    "- **Recursive**:\n",
    "\t- One model is used for the entire forecast horizon. \n",
    "\t- training: The model is trained to predict one point ahead.\n",
    "\t- prediction: The model iteratively predicts each point, using previous predictions to update the features in the test data.\n",
    "\t- Note 1: There is an option to use a “reduced” version, where features are generated for all test observations at once, and unavailable values are filled with NaN.\n",
    "\t- Note 2: Recursive can also be combined with the MIMO strategy, allowing the model to predict model_horizon points ahead at each step.\n",
    "\n",
    "- **Direct**:\n",
    "\t- Individual models are trained for each point in the forecast horizon.\n",
    "\t- Note 1: There is an option to use \"equal_train_size\" option, where all models can be trained on the same X_train set, formed for the last model predicting h point. Only the target variable (y) is updated for each model, reducing the time spent generating new training sets.\n",
    "\t- Note 2: Direct can also be combined with MIMO, where each individual model predicts model_horizon points ahead.\n",
    "\n",
    "- **MIMO (Multi-input-multi-output)**:\n",
    " \t- One model is trained and used for the entire forecast horizon at once. \n",
    "\t- Note 1: This strategy can also accommodate exogenous features (for local- or global-modelling strategies).\n",
    "\n",
    "- **FlatWideMIMO**:\n",
    "\t- A hybrid of Direct and MIMO. One model is trained, but Direct’s features are deployed across the forecast horizon.\n",
    "\t- Note 1: To use FlatWideMIMO with date-related features, h lags of them must be included (with help of LagTransformer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMO — global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the `MIMO-global` strategy as the base strategy, and from there, we will explore all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.easy_setup(dataset_params, pipeline_easy_params, multivariate=False)\n",
    "\n",
    "strategy = MIMOStrategy(\n",
    "    horizon=horizon,\n",
    "    history=history,\n",
    "    pipeline=pipeline,\n",
    "    trainer=trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
